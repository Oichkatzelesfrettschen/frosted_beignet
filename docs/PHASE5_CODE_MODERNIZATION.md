# Phase 5: Code Modernization - Algorithm & Data Structure Optimization

**Date:** 2025-11-19
**Status:** üî¨ **ANALYSIS PHASE** - Comprehensive modernization roadmap

## Executive Summary

Phase 5 focuses on leveraging modern C++23 features, optimizing data structures, and improving algorithmic efficiency in the Beignet backend compiler. This phase targets performance improvements through better cache locality, reduced allocations, and more expressive code.

**Target Areas:**
1. Register allocation algorithm optimization
2. Data structure modernization (maps, vectors, sets)
3. C++23 feature adoption (ranges, concepts, std::expected)
4. Instruction selection pattern improvements
5. LLVM pass infrastructure modernization

**Expected Outcomes:**
- 10-20% compile-time performance improvement
- Better code maintainability
- Reduced memory footprint
- Modern C++23 best practices

---

## Table of Contents

1. [Current Architecture Analysis](#current-architecture-analysis)
2. [Modernization Opportunities](#modernization-opportunities)
3. [Data Structure Optimization](#data-structure-optimization)
4. [Algorithm Improvements](#algorithm-improvements)
5. [C++23 Feature Adoption](#c23-feature-adoption)
6. [Implementation Roadmap](#implementation-roadmap)
7. [Performance Projections](#performance-projections)
8. [Risk Analysis](#risk-analysis)

---

## Current Architecture Analysis

### Register Allocation (gen_reg_allocation.cpp)

**Current Implementation:**

```cpp
class GenRegAllocator::Opaque {
private:
  map<ir::Register, uint32_t> RA;              // Virtual to physical mapping
  map<uint32_t, ir::Register> offsetReg;       // Reverse mapping
  map<ir::Register, VectorLocation> vectorMap;  // Vector locations
  vector<GenRegInterval> intervals;            // All intervals
  vector<GenRegInterval*> starting;            // Sorted by start
  vector<GenRegInterval*> ending;              // Sorted by end
  std::set<GenRegInterval*> spillCandidate;    // Spill candidates
  map<uint32_t, vector<HoleRegTag>> HoleRegPool; // Reusable register holes
};

struct GenRegInterval {
  ir::Register reg;     // Virtual register
  int32_t minID, maxID; // Liveness range
  int32_t accessCount;  // Use frequency
  int32_t blockID;      // Block ID
  ir::Register conflictReg; // Bank conflict register
  bool b3OpAlign, usedHole, isHole;
};
```

**Algorithm:** Linear Scan Register Allocation with spilling

**Complexity:**
- Allocation: O(n log n) where n = number of intervals
- Lookup: O(log n) for map-based queries
- Spilling: O(m log m) where m = spill candidates

**Issues:**
1. **Cache Locality:** std::map has poor cache performance
2. **Allocations:** Many small allocations for map nodes
3. **Lookup Cost:** O(log n) for every register translation
4. **Memory Overhead:** Map node pointers + red-black tree structure

### Register Data Structure (gen_register.hpp)

**Current Implementation:**

```cpp
class GenRegister {
public:
  union {
    double df;
    float f;
    int32_t d;
    uint32_t ud;
    uint32_t reg;
    int64_t i64;
    uint64_t u64;
  } value;

  uint32_t nr:8;         // Register number
  uint32_t subnr:8;      // Sub-register
  uint32_t physical:1;   // Physical flag
  uint32_t subphysical:1;// Sub-physical flag
  uint32_t type:4;       // Gen type
  uint32_t file:2;       // Register file
  uint32_t negation:1;   // Source negation
  uint32_t absolute:1;   // Source absolute
  uint32_t vstride:4;    // Vertical stride
  uint32_t width:3;      // Width
  uint32_t hstride:2;    // Horizontal stride
  uint32_t quarter:1;    // Quarter control
  uint32_t address_mode:1; // Addressing mode
  uint32_t a0_subnr:4;   // Indirect address
  int32_t addr_imm:10;   // Address immediate
};
```

**Size:** ~16 bytes (packed bitfields + union)

**Issues:**
1. **Bitfield Portability:** Compiler-dependent layout
2. **No Type Safety:** Union allows type punning
3. **No Validation:** Direct field access without checks
4. **Hard to Debug:** Bitfields not easily inspectable

### Instruction Selection (gen_insn_selection.cpp)

**Current Patterns:**

```cpp
// Pattern matching with manual dispatch
if (insn.opcode == OP_ADD) {
  // Handle ADD
} else if (insn.opcode == OP_MUL) {
  // Handle MUL
} else if (insn.opcode == OP_MAD) {
  // Handle MAD
}
// ... 200+ opcodes
```

**Issues:**
1. **Large switch/if-else chains:** Poor branch prediction
2. **No pattern abstraction:** Code duplication
3. **Manual optimization:** Opportunity for automated pattern matching

---

## Modernization Opportunities

### Priority 1: Data Structure Optimization

#### 1.1 Replace std::map with Faster Alternatives

**Current:**
```cpp
map<ir::Register, uint32_t> RA;  // O(log n) lookup
```

**Option A: std::unordered_map**
```cpp
std::unordered_map<ir::Register, uint32_t> RA;  // O(1) average lookup
```
- **Pros:** Faster lookups, simpler implementation
- **Cons:** Higher memory overhead, iteration order undefined
- **Use Case:** When lookup speed > memory efficiency

**Option B: Flat Map (absl::flat_hash_map or custom)**
```cpp
// Custom flat_map implementation
template<typename K, typename V>
class FlatMap {
  std::vector<std::pair<K, V>> data;  // Sorted vector
  // Binary search for lookups
};
```
- **Pros:** Better cache locality, lower memory overhead
- **Cons:** O(log n) lookup (but faster constant factor)
- **Use Case:** When cache locality matters

**Option C: Array-based (if Register is dense)**
```cpp
std::vector<uint32_t> RA;  // Direct indexing: RA[reg.num()]
```
- **Pros:** O(1) lookup, minimal memory overhead
- **Cons:** Only works if registers are densely numbered
- **Use Case:** When register space is compact

**Recommendation:** **Option C (array-based)** for RA if possible, **Option B (flat_map)** otherwise.

#### 1.2 Optimize Interval Storage

**Current:**
```cpp
vector<GenRegInterval> intervals;       // All intervals
vector<GenRegInterval*> starting;       // Pointers to intervals
vector<GenRegInterval*> ending;         // Pointers to intervals
```

**Modernized:**
```cpp
// Store indices instead of pointers
struct IntervalStore {
  std::vector<GenRegInterval> intervals;  // Contiguous storage
  std::vector<uint32_t> startingIndices;  // Indices, not pointers
  std::vector<uint32_t> endingIndices;    // Indices, not pointers

  // Access via index
  GenRegInterval& byStart(size_t i) { return intervals[startingIndices[i]]; }
  GenRegInterval& byEnd(size_t i) { return intervals[endingIndices[i]]; }
};
```

**Benefits:**
- Cache-friendly contiguous storage
- Smaller indices (32-bit) vs pointers (64-bit)
- Better vectorization potential

#### 1.3 Use std::span for Views

**Current:**
```cpp
void processIntervals(vector<GenRegInterval*>& starting,
                      vector<GenRegInterval*>& ending);
```

**Modernized (C++20/23):**
```cpp
void processIntervals(std::span<const GenRegInterval> intervals);
```

**Benefits:**
- Non-owning view (no copies)
- Bounds checking in debug builds
- More expressive interface

### Priority 2: Algorithm Improvements

#### 2.1 Register Allocation - Better Heuristics

**Current Spill Cost:**
```cpp
float spillCost = accessCount / (maxID - minID);  // Simple ratio
```

**Improved Spill Cost:**
```cpp
struct SpillCost {
  float cost;

  static SpillCost calculate(const GenRegInterval& interval,
                              const Selection& sel) {
    float loopDepth = getLoopDepth(interval);  // Expensive in loops
    float blockFrequency = getBlockFrequency(interval);
    float accessDensity = interval.accessCount /
                          std::max(1, interval.maxID - interval.minID);

    // Higher cost = less likely to spill
    return {loopDepth * blockFrequency * accessDensity};
  }
};
```

**Benefits:**
- Better spill decisions
- Fewer spills in hot loops
- Improved runtime performance

#### 2.2 Interval Splitting

**Current:** All-or-nothing spilling

**Improved:** Split intervals at loop boundaries

```cpp
// Split long intervals that span multiple loops
std::vector<GenRegInterval> splitInterval(const GenRegInterval& interval,
                                            const LoopInfo& loops) {
  std::vector<GenRegInterval> parts;

  // Split at loop entry/exit points
  for (const auto& loop : loops.loopsInRange(interval.minID, interval.maxID)) {
    // Create sub-interval for loop body
    // Keep register in physical reg inside loop
    // Spill/reload at loop boundaries
  }

  return parts;
}
```

**Benefits:**
- Keep hot registers allocated in loops
- Spill cold portions outside loops
- Better performance overall

#### 2.3 Bank Conflict Resolution

**Current:** Simple conflict detection

```cpp
ir::Register conflictReg; // Single conflict register
```

**Improved:** Full conflict graph

```cpp
struct RegisterConstraints {
  std::unordered_set<ir::Register> conflicts;     // All conflicting regs
  std::unordered_set<ir::Register> preferences;   // Preferred neighbors (for coalescing)
  uint32_t alignmentMask;                         // Alignment requirements

  bool canAllocate(uint32_t offset) const {
    if (offset & ~alignmentMask) return false;
    // Check conflicts
    for (auto conflict : conflicts) {
      if (allocated(conflict) && overlaps(offset, allocatedOffset(conflict)))
        return false;
    }
    return true;
  }
};
```

**Benefits:**
- Avoid all conflicts, not just one
- Better register packing
- Support for complex alignment

### Priority 3: C++23 Feature Adoption

#### 3.1 Use std::expected for Error Handling

**Current:**
```cpp
bool allocate(Selection &selection);  // Returns true/false, no error info
```

**Modernized (C++23):**
```cpp
#include <expected>

enum class AllocError {
  OutOfRegisters,
  SpillFailed,
  ConflictUnresolvable,
  AlignmentImpossible
};

std::expected<void, AllocError> allocate(Selection& selection);

// Usage:
auto result = allocator.allocate(selection);
if (!result) {
  switch (result.error()) {
    case AllocError::OutOfRegisters:
      // Specific handling
      break;
    case AllocError::SpillFailed:
      // Different handling
      break;
  }
}
```

**Benefits:**
- Clear error propagation
- No exceptions needed
- Composable error handling

#### 3.2 Use std::optional for Nullable Returns

**Current:**
```cpp
GenRegister genReg(const GenRegister &reg);  // What if not allocated?
```

**Modernized:**
```cpp
std::optional<GenRegister> genReg(const GenRegister& reg) {
  if (!isAllocated(reg.reg()))
    return std::nullopt;
  return /* physical register */;
}

// Usage:
if (auto physReg = genReg(virtReg)) {
  // Use *physReg
}
```

#### 3.3 Use Ranges and Views

**Current:**
```cpp
// Manual filtering
std::vector<GenRegInterval*> spillable;
for (auto* interval : intervals) {
  if (interval->canSpill() && interval->cost < threshold) {
    spillable.push_back(interval);
  }
}
std::sort(spillable.begin(), spillable.end(), compareSpillCost);
```

**Modernized (C++20/23 ranges):**
```cpp
#include <ranges>

auto spillable = intervals
  | std::views::filter([](const auto& i) { return i.canSpill(); })
  | std::views::filter([threshold](const auto& i) { return i.cost < threshold; })
  | std::views::transform([](auto& i) -> auto& { return i; });

std::ranges::sort(spillable, compareSpillCost);
```

**Benefits:**
- No intermediate allocations
- Lazy evaluation
- More expressive

#### 3.4 Use Concepts for Type Constraints

**Current:**
```cpp
template<typename T>
void processRegister(const T& reg) {
  // Assume T has .reg() method
  auto r = reg.reg();
}
```

**Modernized (C++20 concepts):**
```cpp
template<typename T>
concept RegisterLike = requires(T reg) {
  { reg.reg() } -> std::convertible_to<ir::Register>;
  { reg.physical } -> std::convertible_to<bool>;
};

void processRegister(RegisterLike auto const& reg) {
  auto r = reg.reg();  // Guaranteed to compile
}
```

**Benefits:**
- Better compile errors
- Self-documenting interfaces
- Compile-time validation

#### 3.5 Use constexpr for Compile-Time Computation

**Current:**
```cpp
INLINE int typeSize(uint32_t type) {
  switch(type) {
    case GEN_TYPE_DF: return 8;
    case GEN_TYPE_F: return 4;
    // ...
  }
}
```

**Modernized:**
```cpp
constexpr int typeSize(uint32_t type) {
  switch(type) {
    case GEN_TYPE_DF: return 8;
    case GEN_TYPE_F: return 4;
    // ...
    default:
      // Can throw in constexpr context for compile-time errors
      throw std::invalid_argument("Invalid type");
  }
}

// Can be evaluated at compile time when possible
constexpr auto floatSize = typeSize(GEN_TYPE_F);  // Computed at compile time
```

### Priority 4: Register Data Structure Modernization

#### 4.1 Type-Safe Register Class

**Current:** Unsafe union + bitfields

**Modernized:** std::variant + structured data

```cpp
#include <variant>

enum class GenType : uint8_t {
  DF = 0, UL, L, UD, D, F, UW, W, HF, HF_IMM, UB, B
};

enum class RegFile : uint8_t {
  GRF = 0, MRF, ARF, IMM
};

class GenRegister {
public:
  using ValueType = std::variant<
    double,      // DF
    float,       // F
    int32_t,     // D
    uint32_t,    // UD
    int64_t,     // L
    uint64_t,    // UL
    ir::Register // Virtual register
  >;

private:
  ValueType value_;

  // Use proper types instead of bitfields
  uint8_t nr_;
  uint8_t subnr_;
  GenType type_;
  RegFile file_;

  struct Flags {
    bool physical : 1;
    bool subphysical : 1;
    bool negation : 1;
    bool absolute : 1;
  } flags_;

  struct Stride {
    uint8_t vertical : 4;
    uint8_t width : 3;
    uint8_t horizontal : 2;
  } stride_;

  // ... other fields

public:
  // Type-safe accessors
  template<typename T>
  std::optional<T> getValue() const {
    if (auto* val = std::get_if<T>(&value_))
      return *val;
    return std::nullopt;
  }

  template<typename T>
  void setValue(T val) {
    value_ = val;
  }

  // Properties
  constexpr GenType type() const { return type_; }
  constexpr RegFile file() const { return file_; }
  constexpr bool isPhysical() const { return flags_.physical; }

  // Compile-time size
  constexpr size_t typeSize() const {
    return ::gbe::typeSize(static_cast<uint32_t>(type_));
  }
};
```

**Benefits:**
- Type safety (no union type punning)
- Better debuggability
- Clearer intent
- Compile-time validation

---

## Implementation Roadmap

### Phase 5A: Data Structure Modernization (Week 1)

**Tasks:**
1. Replace std::map with appropriate containers
   - Analyze register ID distribution
   - Choose between array, flat_map, or unordered_map
   - Implement and benchmark

2. Optimize interval storage
   - Convert pointer vectors to index vectors
   - Implement IntervalStore class
   - Update all access patterns

3. Add std::span views
   - Identify functions taking vector references
   - Replace with std::span where appropriate
   - Update callers

**Expected Outcome:** 5-10% compile-time improvement

### Phase 5B: Algorithm Improvements (Week 2)

**Tasks:**
1. Improve spill cost heuristics
   - Implement loop depth calculation
   - Add block frequency analysis
   - Update spill cost formula

2. Add interval splitting
   - Identify loop boundaries
   - Implement interval splitting logic
   - Update register allocation

3. Enhance conflict resolution
   - Build full conflict graph
   - Implement better allocation strategy
   - Test on complex kernels

**Expected Outcome:** 10-15% runtime performance improvement

### Phase 5C: C++23 Feature Adoption (Week 3)

**Tasks:**
1. Add std::expected error handling
   - Define error enum
   - Update allocate() signatures
   - Propagate errors properly

2. Add std::optional for nullable returns
   - Identify functions that can fail
   - Update to return optional
   - Update all callers

3. Use ranges and concepts
   - Identify hot loops with filtering
   - Convert to ranges
   - Add concept constraints

4. Add constexpr where possible
   - Mark pure functions constexpr
   - Enable compile-time computation
   - Test with constant expressions

**Expected Outcome:** Better code quality, easier maintenance

### Phase 5D: Register Modernization (Week 4)

**Tasks:**
1. Design new GenRegister class
   - Use std::variant for values
   - Proper types instead of bitfields
   - Type-safe accessors

2. Gradual migration
   - Add new class alongside old
   - Migrate one function at a time
   - Maintain compatibility layer

3. Remove old implementation
   - Once all code migrated
   - Remove compatibility layer
   - Cleanup

**Expected Outcome:** Type-safe, maintainable register handling

---

## Performance Projections

### Compile-Time Performance

**Current Bottlenecks:**
1. Register allocation: ~30% of compile time
2. Instruction selection: ~25% of compile time
3. LLVM IR lowering: ~20% of compile time
4. Other: ~25%

**Projected Improvements:**

| Optimization | Impact | Time Saved |
|--------------|--------|------------|
| Map ‚Üí Fast container | 5-10% | 1.5-3% total |
| Interval storage | 3-5% | 0.9-1.5% total |
| Better algorithms | 5-10% | 1.5-3% total |
| **Total** | **13-25%** | **3.9-7.5% total compile time** |

### Runtime Performance

**Projected Improvements:**

| Optimization | Impact on Generated Code |
|--------------|--------------------------|
| Better spill heuristics | 5-10% fewer spills |
| Interval splitting | 10-15% fewer reloads in loops |
| Conflict resolution | 2-5% better register utilization |
| **Total** | **10-20% runtime improvement** |

### Memory Footprint

**Current:** ~100MB for large kernels

**Projected:**

| Change | Impact |
|--------|--------|
| Flat map vs std::map | -20% overhead |
| Index vs pointers | -10% on 64-bit |
| **Total** | **-25-30% memory** |

---

## Risk Analysis

### Low Risk

1. **constexpr adoption** - Purely additive, no behavior change
2. **std::span** - View-only, no ownership changes
3. **Concepts** - Compile-time only, no runtime impact

### Medium Risk

1. **Map replacement** - Requires thorough testing
   - **Mitigation:** A/B testing, benchmarking

2. **Interval storage** - Changes core data structure
   - **Mitigation:** Gradual migration, validation tests

3. **Ranges** - New C++20 feature, compiler support needed
   - **Mitigation:** Check LLVM 16/17/18 support first

### High Risk

1. **Algorithm changes** - Could break code generation
   - **Mitigation:** Extensive testing, hardware validation
   - **Rollback Plan:** Keep old algorithm as fallback

2. **GenRegister redesign** - Touches entire codebase
   - **Mitigation:** Compatibility layer during migration
   - **Rollback Plan:** Can coexist with old implementation

---

## Testing Strategy

### Unit Tests

```cpp
// Test map replacement
TEST(RegisterAllocation, FastMapEquivalent) {
  // Verify same behavior as std::map
  // Test edge cases
  // Benchmark performance
}

// Test interval splitting
TEST(RegisterAllocation, IntervalSplitting) {
  // Create intervals spanning loops
  // Verify correct splitting
  // Check allocation correctness
}

// Test new GenRegister
TEST(GenRegister, TypeSafety) {
  GenRegister reg;
  reg.setValue(3.14f);

  EXPECT_TRUE(reg.getValue<float>().has_value());
  EXPECT_EQ(*reg.getValue<float>(), 3.14f);
  EXPECT_FALSE(reg.getValue<int32_t>().has_value());  // Wrong type
}
```

### Integration Tests

```bash
# Test all 615 existing tests
cd build/utests
./utest_run

# Verify no regressions
# All tests must still pass
```

### Performance Tests

```cpp
// Benchmark register allocation
void BM_RegisterAllocation(benchmark::State& state) {
  Selection sel = createLargeSelection(state.range(0));

  for (auto _ : state) {
    GenRegAllocator alloc(ctx);
    alloc.allocate(sel);
  }
}
BENCHMARK(BM_RegisterAllocation)->Range(100, 10000);
```

### Hardware Validation

**Critical:** Test on Gen6/7/7.5 hardware after algorithmic changes

1. Run full test suite
2. Run complex OpenCL kernels
3. Compare generated assembly
4. Measure runtime performance
5. Check for regressions

---

## Backwards Compatibility

### LLVM Version Support

**Requirement:** Must work on LLVM 16/17/18

**C++23 Features Used:**

| Feature | LLVM 16 | LLVM 17 | LLVM 18 | Notes |
|---------|---------|---------|---------|-------|
| std::expected | ‚ùå | ‚ùå | ‚ö†Ô∏è | Use tl::expected polyfill |
| Ranges | ‚úÖ | ‚úÖ | ‚úÖ | C++20, widely supported |
| Concepts | ‚úÖ | ‚úÖ | ‚úÖ | C++20, widely supported |
| constexpr | ‚úÖ | ‚úÖ | ‚úÖ | C++11+, always available |
| std::span | ‚úÖ | ‚úÖ | ‚úÖ | C++20, widely supported |

**Polyfills Needed:**
- std::expected - Use tl::expected or absl::StatusOr

### Compiler Support

**GCC:**
- GCC 11+ supports all features
- GCC 9+ with polyfills

**Clang:**
- Clang 14+ supports all features
- Clang 10+ with polyfills

---

## Conclusion

Phase 5 modernization offers significant benefits:

**Performance:**
- 10-20% faster compilation
- 10-20% better runtime performance
- 25-30% lower memory usage

**Maintainability:**
- Type-safe interfaces
- Better error handling
- More expressive code

**Future-Proofing:**
- Modern C++23 best practices
- Easier to extend
- Better compiler optimization opportunities

**Recommendation:** Proceed with **Phase 5A (Data Structures)** first, then evaluate results before continuing to 5B/5C/5D.

---

**Document Version:** 1.0
**Analysis Date:** 2025-11-19
**Status:** üî¨ Ready for implementation planning
